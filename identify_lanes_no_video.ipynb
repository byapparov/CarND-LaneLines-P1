{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'extend_line' from 'src.traffic_lanes_pipeline.merge_lines' (/Users/byapparov/Documents/code/udacity/CarND-LaneLines-P1/src/traffic_lanes_pipeline/merge_lines.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-14a45f20f5c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraffic_lanes_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_lines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextend_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraffic_lanes_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextend_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraffic_lanes_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_filter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlimit_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'extend_line' from 'src.traffic_lanes_pipeline.merge_lines' (/Users/byapparov/Documents/code/udacity/CarND-LaneLines-P1/src/traffic_lanes_pipeline/merge_lines.py)"
     ]
    }
   ],
   "source": [
    "# conda install -c menpo opencv\n",
    "# https://stackoverflow.com/questions/23119413/how-do-i-install-python-opencv-through-conda\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "from src.traffic_lanes_pipeline.merge_lines import merge_lines, extend_line\n",
    "from src.traffic_lanes_pipeline.lanes import extend_line\n",
    "from src.traffic_lanes_pipeline.view_filter import limit_view\n",
    "from src.traffic_lanes_pipeline.image_pipeline import process_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greyscale the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test_images/solidYellowLeft.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "# This is to compensate for the fact that \n",
    "# opencv image layers are stored in reverse order - BGR\n",
    "# @alsosee https://www.pyimagesearch.com/2014/11/03/display-matplotlib-rgb-image/\n",
    "img_color = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_color)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# cmap, vmin, vmax allow to print image as human expects it\n",
    "plt.imshow(img_grey, cmap=cm.gray, vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply gradient filter to identify edges\n",
    "\n",
    "Gradient filter can be applied to the grey scale image to identify\n",
    "points on the where color intensity changes the most. \n",
    "\n",
    "On this example image these we can expect bright road lines to be picked \n",
    "up by the filter. \n",
    "\n",
    "Application of the GaussianBlur prior to Edge detection\n",
    "reduces number of edgets that will be identified in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a kernel size for Gaussian smoothing / blurring\n",
    "# Note: this step is optional as cv2.Canny() applies a 5x5 Gaussian internally\n",
    "kernel_size = 5\n",
    "img_blur = cv2.GaussianBlur(img_grey,(kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thresholds = [(50, 150), (50, 200), (30, 200), (70, 200), \n",
    "              (50, 180), (50, 220), (50, 250),\n",
    "              (100, 150), (100, 200), (100, 250),\n",
    "              (150, 150), (150, 200), (150, 250)]\n",
    "\n",
    "\n",
    "for l, h in thresholds:\n",
    "    img_gradient = cv2.Canny(img_blur, l, h)\n",
    "    cv2.putText(\n",
    "        img_gradient, \n",
    "        \"Thresholds (l,h): {l}, {h}\".format(l = l, h = h), \n",
    "        (50,50), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "        1, \n",
    "        255\n",
    "    )\n",
    "    cv2.imwrite(\n",
    "        \"writeup_images/img_canny_tunning_{l}_{h}.jpg\".format(l = l, h = h), \n",
    "        img_gradient\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholds | Lower 50 | Lower 100 | Lower 150\n",
    ":-------|:--------------------------:|:--------------------------:|:--------------------------:\n",
    "Upper 150 |![Canny 50 150](writeup_images/img_canny_tunning_50_150.jpg) | ![Canny 100 150](writeup_images/img_canny_tunning_100_150.jpg) | ![Canny 150 200](writeup_images/img_canny_tunning_150_150.jpg)\n",
    "Upper 200 |![Canny 50 200](writeup_images/img_canny_tunning_50_200.jpg) | ![Canny 100 150](writeup_images/img_canny_tunning_100_200.jpg) | ![Canny 150 200](writeup_images/img_canny_tunning_150_200.jpg)\n",
    "Upper 250 |![Canny 50 250](writeup_images/img_canny_tunning_50_250.jpg) | ![Canny 100 250](writeup_images/img_canny_tunning_100_250.jpg) | ![Canny 150 250](writeup_images/img_canny_tunning_150_250.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_threshold = 50\n",
    "high_threshold = 200\n",
    "img_gradient = cv2.Canny(img_blur, low_threshold, high_threshold)\n",
    "\n",
    "plt.imshow(img_gradient, cmap='Greys_r')\n",
    "\n",
    "\n",
    "cv2.imwrite(\n",
    "    \"writeup_images/img_gradient.jpg\", \n",
    "    img_gradient\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce image scope\n",
    "\n",
    "To detect lanes on the road it will help to reduce the view\n",
    "of the camera to the road ahead of the car which can be asumed \n",
    "to be a triangle formed between:\n",
    "\n",
    " - left bottom corner of the image\n",
    " - right bottom corner\n",
    " - point in the middle by x and 2/3 from the bottom by y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo output of the `limit_view()` function\n",
    "img_view_demo = np.copy(img_grey) * 0 #creating a blank to draw lines on\n",
    "img_view_demo = limit_view(img_view_demo, color = 255) # remove color outside of the road view\n",
    "plt.imshow(img_view_demo, cmap='Greys_r')\n",
    "\n",
    "cv2.imwrite(\n",
    "    \"writeup_images/img_view_demo.jpg\", \n",
    "    img_view_demo\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_limited_view = limit_view(img_gradient)  \n",
    "plt.imshow(img_limited_view, cmap='Greys_r')\n",
    "\n",
    "\n",
    "cv2.imwrite(\n",
    "    \"writeup_images/img_limited_view.jpg\", \n",
    "    img_limited_view\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hough transform parameters\n",
    "# Make a blank the same size as our image to draw on\n",
    "rho = 1\n",
    "theta = np.pi / 180\n",
    "threshold = 50\n",
    "min_line_length = 100\n",
    "max_line_gap = 50\n",
    "\n",
    "line_image = np.copy(img_limited_view) * 0 #creating a blank to draw lines on\n",
    "\n",
    "# Run Hough on edge detected image\n",
    "# OpenCV contains explanation of theory and parameters for HoughLinesP\n",
    "# https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html\n",
    "lines = cv2.HoughLinesP(\n",
    "    img_limited_view, rho, theta, threshold, np.array([]),\n",
    "                            min_line_length, max_line_gap)\n",
    "\n",
    "print(\"Lines detected: {lines}\".format(lines = len(lines)))\n",
    "                  \n",
    "lines_output = merge_lines(lines)\n",
    "\n",
    "\n",
    "print(\"Lines merged into: {output}\".format(output = len(lines_output)))\n",
    "\n",
    "height, width = img_grey.shape\n",
    "\n",
    "# Iterate over the output \"lines\" and draw lines on the blank\n",
    "for line in lines_output:\n",
    "    el = extend_line(line, height, width)\n",
    "    print(el)\n",
    "    for x1, y1, x2, y2 in el:\n",
    "        cv2.line(line_image, (x1, y1), (x2, y2), 255, 10)\n",
    "        \n",
    "        \n",
    "plt.imshow(line_image)        \n",
    "        \n",
    "# Create a \"color\" binary image to combine with line image\n",
    "color_edges = np.dstack((img_limited_view, img_limited_view, img_limited_view)) \n",
    "\n",
    "plt.imshow(color_edges)\n",
    "line_image = cv2.merge((np.copy(img_limited_view) * 0, np.copy(img_limited_view) * 0, line_image))\n",
    "# Draw the lines on the edge image\n",
    "combo = cv2.addWeighted(color_edges, 0.8, line_image, 1, 0) \n",
    "plt.imshow(combo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result \n",
    "\n",
    "Now we can combine lines derived from the pipeline above with original image to visually evaulate performance of the algorithm. \n",
    "        \n",
    "In this example result is only partially satisfactory:\n",
    "\n",
    "* Continious line on the right side is identified completely\n",
    "* First section of the broken line on the left side is identified\n",
    "\n",
    "\n",
    "However, most of segments of the broken line on the left side are undetected. \n",
    "\n",
    "There are possible ares for research to improve this:\n",
    "\n",
    " * Apply Canny edge detection to the relevant part of the image with different threshold level\n",
    " * Apply line detection iteratively over the depth of the image with different threshold levels\n",
    "   to capture smaller \n",
    " * Interpolate broken lines using the perspective geometry. This pottentially can inform about the shape of the lane based on the other line(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_demo = img.copy()\n",
    "img_demo = cv2.addWeighted(img, 0.8, line_image, 1, 0) \n",
    "img_demo_color = cv2.cvtColor(img_demo, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_demo_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test_images/solidYellowLeft.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "res = img_demo2 = process_image(img)\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test_images/challenge.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "res = img_demo2 = process_image(img)\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-db40c033be68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_images/challenge2.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_demo2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_image' is not defined"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('test_images/challenge2.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "res = img_demo2 = process_image(img)\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = [[2, 6, 4, 8]]\n",
    "res = extend_line(line, 10, 10)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:udacity]",
   "language": "python",
   "name": "conda-env-udacity-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
